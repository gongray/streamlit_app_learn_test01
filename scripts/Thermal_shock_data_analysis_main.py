#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''
@Project ï¼šstreamlit_project 
@File    ï¼šthermal_shock_daata_analysis.py
@Author  ï¼šRay Gong
@Date    ï¼š2024/4/3 22:31 
'''
import streamlit as st
import pandas as pd
import os
import time
# import base64
# import plotly.figure_factory as ff
# import traceback
import plotly.express as px
import plotly.io as pio
# from bs4 import BeautifulSoup
# pip install beautifulsoup4
# from subscript import read_csvs, Temperature_curve_plot_V02

time_column_candidates = ['Time', 'time', 'æ—¶é—´'] # csvä¸­å¯èƒ½çš„æ—¶é—´åˆ—åç§°

# def modify_html(html):
#     # æ‰“å¼€å¹¶è¯»å–HTMLæ–‡ä»¶
#     file_path = html
#     with open(file_path, 'r', encoding='utf-8') as file:
#         soup = BeautifulSoup(file, 'html.parser')
#
#     scripts = soup.find_all('script')
#
#     url = 'https://plotly.com/'
#     for script in scripts:
#         # å‡è®¾æˆ‘ä»¬çŸ¥é“URLæ˜¯åœ¨ä¸€ä¸ªæ˜ç¡®çš„å­—ç¬¦ä¸²ä¸­
#         if url in script.string:
#             new_url = 'http://bing.com'
#             # ä½¿ç”¨replace()æ–¹æ³•æ›¿æ¢æ—§URLä¸ºæ–°URL
#             updated_script = script.string.replace(url, new_url)
#             script.string.replace_with(updated_script)
#         elif 'Produced with ' in script.string:
#             updated_script = script.string.replace('Produced with ', ' ')
#             script.string.replace_with(updated_script)
#     # file_path = 'output1.html'
#     # å°†ä¿®æ”¹åçš„HTMLå†™å›æ–‡ä»¶
#     with open(file_path, 'w', encoding='utf-8') as file:
#         file.write(str(soup.prettify()))

def plot_curve(df, interal, xcolumn_name, ycolumn_names, output_html):
    print('å‡†å¤‡å¼€å§‹ç”»æ›²çº¿ï¼')
    if interal:
        df1 = df.iloc[::interal]
    df1 = df1.reset_index()
    if xcolumn_name == None:
        xcolumn_name = '_Index'
        df1.loc[:, '_Index'] = df1.index
    # print(df.shape, xcolumn_name, ycolumn_names)
    # print(df.columns)
    fig = px.line(df1, x=xcolumn_name, y=ycolumn_names)
    # fig.update_xaxes(tickformat='%Y-%m-%d %H:%M:%S', type='date')
    # fig.update_layout(title=figure_title, xaxis_title=' ', yaxis_title=' ')

    # # å°†å›¾è¡¨å¯¼å‡ºä¸ºHTMLæ–‡ä»¶
    # pio.write_html(fig, file='output.html', auto_open=True)
    # å¦‚æœä¸å¸Œæœ›è‡ªåŠ¨æ‰“å¼€æ–‡ä»¶ï¼Œå¯ä»¥è¿™æ ·è°ƒç”¨ï¼š
    pio.write_html(fig, file=output_html, auto_open=False)
    # if os.path.exists(output_html):
    #     modify_html(output_html)

    # fig.show()
    print(f'ç”»å›¾å®Œæ¯•, ç”Ÿæˆæ–‡ä»¶ï¼š{output_html}')


def duplicated_time(dup_df, time_colname):
    all_time = pd.Series()
    count_dupli = dup_df[time_colname].value_counts()
    # print(count_dupli)
    for idx, val in count_dupli.items():
        if val > 60:
            print('Error!æ—¶é—´åˆ—ç›¸åŒæ—¶é—´è¶…è¿‡60è¡Œï¼Œæ— æ³•é‡å»ºæ—¶é—´åˆ—ï¼å¯¹åº”çš„æ—¶é—´ç‚¹ä¸ºï¼š', idx)
            break
        elif val == 1:
            series_of_seconds = pd.to_datetime(pd.Series([idx]))
            # all_time = pd.concat([all_time, series_of_seconds])
        else:
            # è®¾ç½®èµ·å§‹æ—¶é—´
            start_time = pd.Timestamp(idx)

            # ç»“æŸæ—¶é—´æ˜¯èµ·å§‹æ—¶é—´ä¹‹å1åˆ†é’Ÿ
            end_time = start_time + pd.Timedelta(minutes=1)

            # ä½¿ç”¨date_rangeç”Ÿæˆè¿™ä¸€åˆ†é’Ÿå†…æ¯ç§’çš„æ—¶é—´æˆ³åºåˆ—
            timestamps = pd.date_range(start=start_time, end=end_time - pd.Timedelta(seconds=1),
                                       freq='s')
            # print(timestamps)
            # è¾“å‡ºç»“æœ
            # for ts in timestamps:
            #     print(ts.strftime('%Y-%m-%d %H:%M:%S'))

            # æˆ–è€…å°†å®ƒä»¬è½¬æ¢æˆSeriesä»¥ä¾¿è¿›ä¸€æ­¥æ“ä½œ
            series_of_seconds = pd.Series(timestamps)[:val]
        if len(all_time):
            all_time = pd.concat([all_time, series_of_seconds])
        else:
            all_time = series_of_seconds
    else:
        return None
            
    # print(all_time.dtypes)
    all_time = all_time.sort_values()
    return all_time.values()
    
    
def process_uploaded_file(file):
    filename = file.name
    st.write('æ­£åœ¨å¤„ç†csvæ–‡ä»¶ï¼š', filename)
    # detected_encoding = detect_encoding(file)
    # print('è·å–äº†ç¼–ç è§„åˆ™ï¼š', detected_encoding)
    try:
        df_temp = pd.read_csv(file, encoding='gbk')
        na_rows = df_temp.isnull().any(axis=1)
        if na_rows.any():
            st.write('!!!å‘ç°å­˜åœ¨NAè¡Œï¼Œå°†å¿½ç•¥è¿™äº›è¡Œï¼š')
            st.write(df_temp[na_rows])
            df_temp = df_temp[~na_rows]
        time_colname = None
        
        for candidate in time_column_candidates:
            if candidate in df_temp.columns:
                time_colname = candidate
                print('æˆåŠŸè·å–æ—¶é—´åˆ—åç§°ï¼Œåç§°ä¸ºï¼š', time_colname)
                break
        if time_colname is None:
            # st.write('æ— æ³•åœ¨CSVæ–‡ä»¶ä¸­æ£€æµ‹åˆ°æ—¶é—´åˆ—ï¼Œè¯·ç¡®ä¿è‡³å°‘åŒ…å«ä»¥ä¸‹åˆ—åä¹‹ä¸€ï¼š{}'.format(time_column_candidates))
            raise ValueError('æ— æ³•åœ¨CSVæ–‡ä»¶ä¸­æ£€æµ‹åˆ°æ—¶é—´åˆ—ï¼Œè¯·ç¡®ä¿è‡³å°‘åŒ…å«ä»¥ä¸‹åˆ—åä¹‹ä¸€ï¼š{}'.format(time_column_candidates))
        else:
            df_temp[time_colname] = pd.to_datetime(df_temp[time_colname], errors='raise')
            print(f"å°†åˆ—: {time_colname}è½¬æ¢ä¸ºæ—¶é—´æˆåŠŸ")
            # print(df.dtypes)
            if df_temp.duplicated(subset=[time_colname]).any():
                print('ï¼ï¼ï¼æ³¨æ„ï¼šæ—¶é—´åˆ—æœ‰é‡å¤ï¼Œå°†å¯¹é‡å¤çš„æ—¶é—´å°è¯•æŒ‰ç…§1Hzé‡‡æ ·ç‡è¿›è¡Œé‡å»ºã€‚')
                new_time_index = duplicated_time(df_temp, time_colname)
                if new_time_index is not None:
                    print('new_time_index:', len(new_time_index))
                    print('df_temp.index:', len(df_temp.index))
                    df_temp.index = new_time_index
            else:
                df_temp = df_temp.sort_values(by=time_colname)
            
            # å°†æ•°æ®è½¬ä¸ºæ•°å€¼
            successful_numerical_columns = []
            for column in df_temp.columns:
                if column != time_colname:
                    df_temp[column] = pd.to_numeric(df_temp[column], errors='coerce')
                    if df_temp[column].dtype.kind in ('i', 'f'):
                        successful_numerical_columns.append(column)
            if len(successful_numerical_columns) >0:
                if len(successful_numerical_columns)+1 != len(df_temp.columns):
                    st.write('è¯·æ³¨æ„ï¼éƒ¨åˆ†åˆ—æœªæˆåŠŸè½¬æ¢æœªæ•°å€¼ç±»å‹ï¼Œå°†å¿½ç•¥è¿™äº›åˆ—ï¼')
                df_temp = df_temp[[time_colname] + successful_numerical_columns]
                df_temp.rename(columns={time_colname:'time'}, inplace=True)
            else:
                raise ValueError('éæ—¶é—´åˆ—å‡æ— æ³•å®Œå…¨è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œè¯·æ£€æŸ¥ï¼')
    except Exception as e:
        st.write(f'å¤„ç†æ–‡ä»¶"{filename}"æ—¶å‡ºé”™ï¼š{str(e)}')
        print(f"é”™è¯¯å‘ç”Ÿä½ç½®: {e.__traceback__.tb_frame.f_code.co_filename}:{e.__traceback__.tb_lineno}")
        return None
    else:
        st.write(f'æ–‡ä»¶"{filename}"æ ¼å¼æ­£ç¡®ï¼Œ è·å–æ•°æ®ï¼š{df_temp.shape[0]}è¡Œï¼Œ{df_temp.shape[1]}åˆ—ï¼')
        return df_temp

@st.cache_data(ttl=300)
def load_and_process_csvs(uploaded_files):
    all_data = pd.DataFrame()
    for uploaded_file in uploaded_files:
        processed_df = process_uploaded_file(uploaded_file) # å¤„ç†æ˜¯æ—¶åŸŸæ•°æ®ï¼Œå¹¶ä¸”æŠŠæ—¶é—´åˆ—å‘½åä¸º time
        if processed_df is not None:
            if all_data.shape[0] == 0:
                all_data = processed_df
            else:
                if list(all_data.columns) == list(all_data.columns):
                    times_in_all = set(all_data['time'])
                    common_times = processed_df[processed_df['time'].isin(times_in_all)]
                    if not common_times.empty:
                        st.write(f'!!!æ–‡ä»¶"{uploaded_file.name}"ä¸­çš„æ—¶é—´ä¸å…¶ä»–æ–‡ä»¶æœ‰é‡å¤ï¼Œå°†å¿½ç•¥è¯¥æ–‡ä»¶ï¼é‡å¤æ•°æ®å¦‚ä¸‹ï¼š')
                        st.write(common_times)
                    else:
                        all_data = pd.concat([all_data, processed_df], ignore_index=True).sort_values(by='time')
                else:
                    st.write(f'æ–‡ä»¶"{uploaded_file.name}"åˆ—åä¸å…¶ä»–ä¸åŒï¼Œå°†å¿½ç•¥è¯¥æ–‡ä»¶ï¼')
    return all_data

def create_bins(target_temp, _lower, _upper):
    bins = [0, 150]
    for i in range(200, target_temp, 100):
        bins.append(i)
    # print(bins)

    bins.extend([_lower, target_temp, _upper, 10000])
    bins = list(dict.fromkeys(bins))
    bins.sort()

    print(bins)
    return bins

def create_data(data, col_name2cut, bins):
    # # å‡è®¾æœ‰ä¸€ä¸ªDataFrameï¼Œå…¶ä¸­ä¸€åˆ—æ˜¯æ•°å€¼æ•°æ®
    # data = pd.DataFrame({'Values': [1, 3, 6, 8, 10, 15, 17, 20, 22, 25]})
    # # å®šä¹‰åŒºé—´è¾¹ç•Œ
    # bins = [0, 10, 20, 30]
    # åˆ›å»ºæ–°çš„åˆ—ï¼Œå°†æ•°å€¼åˆ’åˆ†åˆ°ä¸åŒçš„åŒºé—´
    data['Bins'] = pd.cut(data[col_name2cut], bins)
    # è®¡ç®—å„åŒºé—´å†…æ•°æ®çš„é¢‘æ•°
    counts = data.groupby('Bins')[col_name2cut].size()
    # è®¡ç®—å„åŒºé—´å æ¯”ï¼ˆç™¾åˆ†æ¯”å½¢å¼ï¼‰
    percentages = counts / counts.sum() * 100
    # è¾“å‡ºå æ¯”ç»“æœ
    print(percentages.values)
    # # å‡è®¾ä½ å·²ç»æœ‰äº†ä¹‹å‰è®¡ç®—å‡ºçš„ç™¾åˆ†æ¯”æ•°æ®ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ç¤ºä¾‹æ•°æ®
    # percentages = pd.Series([30, 40, 30], index=['[0, 10)', '[10, 20)', '[20, 30)'])
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    xi = [str(item) for item in percentages.index]

    return pd.DataFrame({'Intervals': xi, 'Percentage (%)': percentages.values})



def start_thermal_shock_analysis():
    st.set_page_config(
        page_title="Engine Excitation calculation",
        page_icon="ğŸ§Š",
        layout="wide",
        initial_sidebar_state="expanded",
        # menu_items=None
        # menu_items={
        #     'Get Help': None,
        #     'Report a bug': None,
        #     'About': None
        # }
    )
    # éšè—èœå•æ 
    # hide_streamlit_style = """
    # <style>
    # #MainMenu {visibility: hidden;}
    # footer {visibility: hidden;}
    # </style>
    #
    # """
    # st.markdown(hide_streamlit_style, unsafe_allow_html=True)

    # éšè—deployå’Œèœå•æ 
    st.markdown('''
        <style>
        .stApp [data-testid="stToolbar"]{
            display:none;
        }
        </style>
        ''', unsafe_allow_html=True)


    st.title('Thermal Shock Data Visualization')
    # è¾“å…¥å¯†ç éªŒè¯
    # st.markdown("### è¾“å…¥å¯†ç éªŒè¯")
    # password = st.text_input("è¯·è¾“å…¥6ä½æ•°å­—å¯†ç ")
    # if password != "123456":
    #     st.write("å¯†ç é”™è¯¯")
    #     st.stop()
    st.markdown('''
     æ³¨æ„ï¼š
         1. å°†æ¸©åº¦æ•°æ®è½¬ä¸ºcsvæ–‡ä»¶ã€‚
         2. ç¡®ä¿æ‰€æœ‰csvæ–‡ä»¶çš„åˆ—åä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´ï¼Œå°†ä¼šæŠ¥é”™ï¼Œéœ€è¦æ‰‹åŠ¨æ›´æ”¹ã€‚
         3. ç¡®ä¿å­˜åœ¨æ—¶é—´åˆ—ï¼Œä¸”åˆ—åä¸º['Time', 'time', 'æ—¶é—´']ä¹‹ä¸€ã€‚
         4. å¦‚æœæ—¶é—´åˆ—æœ‰é‡å¤ï¼Œå°†æŒ‰ç…§1Hzè¿›è¡Œé‡å»ºã€‚
    ''')
    st.markdown('## :blue[Input CSV read and preprocess]')
    # st.markdown('<font color=#0099ff size=12 face="é»‘ä½“">é»‘ä½“@@@@@@@@@</font>')
    
    uploaded_files = st.file_uploader('Choose the csv files:', accept_multiple_files=True, type='.csv', help=f'éœ€è¦æœ‰{",".join(time_column_candidates)}ä¹‹ä¸€ä½œä¸ºæ—¶é—´åˆ—ï¼')
    # if uploaded_files:
    with st.expander('Waiting for processs csv files, expand for detail.....'):
        all_data = load_and_process_csvs(uploaded_files)
        if all_data.shape[0]:
            st.write(f'å…±è·å–æ•°æ®ï¼š{all_data.shape[0]}è¡Œï¼Œ{all_data.shape[1]}åˆ—')
            st.write(all_data.head())
        else:
            st.write('No data have been read!')

    if all_data.shape[0]:
        st.markdown('## :blue[Time Series Plot]')
        interval = st.slider('Time series interval for plot(For better view):', 0, 120, 10)
        cols_no_time = list(all_data.columns)
        cols_no_time.remove('time')
        colums_choose = st.multiselect('Select the interested columns', cols_no_time)
        folder = os.getcwd()
        fname = f'Time_series_curves_{str(time.time()).replace(".", "-")}.html'
        if st.button('Plot Time Series Curve'):
            print('Ploting!')
            # st.line_chart(all_data[colums_choose], x='time', y=colums_choose)
            select_cols_with_time = colums_choose.copy()
            select_cols_with_time.append('time')
            if interval:
                fig = px.line(all_data[select_cols_with_time].iloc[::interval], x='time', y=colums_choose)
            else:
                fig = px.line(all_data[select_cols_with_time], x='time', y=colums_choose)
            st.plotly_chart(fig, theme=None)
            
            # temp_html_file = "temp_plot.html"
            # pio.write_html(fig, file=temp_html_file, auto_open=False)
            # with open(temp_html_file, 'r', encoding='utf-8') as f:
            #     html_content = f.read()
            # os.remove(temp_html_file)
            
            # # å°†HTMLå†…å®¹è½¬åŒ–ä¸ºå­—èŠ‚ä¸²
            # html_bytes = html_content.encode('utf-8')
            # # åœ¨Streamlitç•Œé¢æ·»åŠ ä¸‹è½½æŒ‰é’®ï¼Œç›´æ¥æä¾›æ•°æ®å’Œæ–‡ä»¶å
            # st.download_button(
            #     label="Download Time Series Curve File",
            #     data=html_bytes,
            #     file_name=temp_html_file,
            #     # mime_type="text/html"
            # )
            # # ä½¿ç”¨Streamlitæä¾›ä¸‹è½½é“¾æ¥
            # b64 = base64.b64encode(html_content.encode()).decode()
            # href = f'<a href="data:text/html;base64,{b64}" download="interactive_plot.html">ä¸‹è½½äº¤äº’å¼å›¾è¡¨ (HTML)</a>'
            # st.markdown(href, unsafe_allow_html=True)

        st.markdown('## :blue[Statistic Plot]')
        selected_col = st.selectbox('Select the column name for plot', [col for col in all_data.columns if col != 'time'])
        method_input_bins = st.radio('Choose the method for bins input', ['Auto', 'Manual Input'])
        if method_input_bins == 'Auto':
            col1, col2, col3 = st.columns(3)
            with col1:
                target_value = st.number_input('The target value', value=0)

            with col2:
                lower_boundary = st.number_input('The lower boundary', value=0)

            with col3:
                upper_boundary = st.number_input('The upper boundary', value=0)
        else:
            bins_str = st.text_input('Input bins (Comma separate)')
        if st.button('Statistic Plot'):
            if method_input_bins == 'Auto':
                if target_value > 0.01 and lower_boundary> 0.01 and upper_boundary > 0.01:
                    bins = create_bins(target_value, lower_boundary, upper_boundary)
                    chart_data = create_data(all_data, selected_col, bins)
                    st.bar_chart(chart_data, x="Intervals", y="Percentage (%)")
                else:
                    st.write('Some of input "data target_value" "lower_boundary" "upper_boundary" is not OK')
            elif method_input_bins == 'Manual Input':
                try:
                    bins = bins_str.split(',')
                    bins = [int(i) for i in bins]
                    if target_value > 0.01 and lower_boundary > 0.01 and upper_boundary > 0.01:
                        chart_data = create_data(all_data, selected_col, bins)
                        st.bar_chart(chart_data, x="Intervals", y="Percentage (%)")
                    else:
                        st.write('Some of input "data target_value" "lower_boundary" "upper_boundary" is not OK')
                except Exception as err:
                    st.write(f'è¾“å…¥çš„Binsæœ‰é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥ï¼å…·ä½“åŸå› ï¼š{err}')

